{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial PySpark Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-29T14:48:40.842621Z",
     "start_time": "2017-06-29T14:48:40.802176Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"ggplot\")\n",
    "%matplotlib inline\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from haversine import haversine\n",
    "from itertools import izip\n",
    "import pyspark as ps\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.types import StructType\n",
    "from pyspark.sql.functions import struct, udf, col\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spark Session and Initial Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-29T14:37:32.976984Z",
     "start_time": "2017-06-29T14:37:25.592360Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spark = ps.sql.SparkSession\\\n",
    "            .builder\\\n",
    "            .master(\"local[4]\")\\\n",
    "            .appName(\"Spark_EDA\")\\\n",
    "            .getOrCreate()\n",
    "            \n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-29T14:37:34.587839Z",
     "start_time": "2017-06-29T14:37:34.541324Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"lat\", FloatType(), True),\n",
    "    StructField(\"lon\", FloatType(), True),\n",
    "    StructField(\"id\", StringType(), True),\n",
    "    StructField(\"source_id\", StringType(), True),\n",
    "    StructField(\"account_id\", StringType(), True),\n",
    "    StructField(\"title\", StringType(), True),\n",
    "    StructField(\"created_on\", IntegerType(), True),\n",
    "    StructField(\"updated_on\", StringType(), True),\n",
    "    StructField(\"start_ts\", IntegerType(), True),\n",
    "    StructField(\"until_ts\", StringType(), True),\n",
    "    StructField(\"report_type\", StringType(), True),\n",
    "    StructField(\"notes\", StringType(), True),\n",
    "    StructField(\"layer_id\", StringType(), True),\n",
    "    StructField(\"severity\", StringType(), True)\n",
    "])\n",
    "\n",
    "target_columns = [\n",
    "    \"lat\",\n",
    "    \"lon\",\n",
    "    \"id\",\n",
    "    \"title\",\n",
    "    \"created_on\",\n",
    "    \"start_ts\",\n",
    "    \"report_type\",\n",
    "    \"notes\",\n",
    "    \"severity\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-29T10:42:15.175259Z",
     "start_time": "2017-06-29T10:42:15.143585Z"
    }
   },
   "source": [
    "### Shell command to clean quoted newlines\n",
    "\n",
    "awk -v RS='\"' 'NR % 2 == 0 { gsub(/\\n/, \" \") } { printf(\"%s%s\", $0, RT) }' input_file > output_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-29T14:37:36.871599Z",
     "start_time": "2017-06-29T14:37:36.840711Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_filepath = \"../data/reports_12DEC16-26DEC16.tsv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-29T14:49:58.161344Z",
     "start_time": "2017-06-29T14:49:58.104638Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def severity_score(severity_rating):\n",
    "    if severity_rating == \"low\":\n",
    "        return 1\n",
    "    elif severity_rating == \"moderate\":\n",
    "        return 2\n",
    "    elif severity_rating == \"medium\":\n",
    "        return 3\n",
    "    elif severity_rating == \"high\":\n",
    "        return 4\n",
    "    elif severity_rating == \"extreme\":\n",
    "        return 5\n",
    "    else:\n",
    "        return 2\n",
    "    \n",
    "def severity_score_quadratic(severity_rating):\n",
    "    if severity_rating == \"low\":\n",
    "        return 1\n",
    "    elif severity_rating == \"moderate\":\n",
    "        return 4\n",
    "    elif severity_rating == \"medium\":\n",
    "        return 9\n",
    "    elif severity_rating == \"high\":\n",
    "        return 16\n",
    "    elif severity_rating == \"extreme\":\n",
    "        return 25\n",
    "    else:\n",
    "        return 4\n",
    "    \n",
    "def severity_score_log(severity_rating):\n",
    "    if severity_rating == \"low\":\n",
    "        return np.log(1)\n",
    "    elif severity_rating == \"moderate\":\n",
    "        return np.log(2)\n",
    "    elif severity_rating == \"medium\":\n",
    "        return np.log(3)\n",
    "    elif severity_rating == \"high\":\n",
    "        return np.log(4)\n",
    "    elif severity_rating == \"extreme\":\n",
    "        return np.log(5)\n",
    "    else:\n",
    "        return np.log(2)\n",
    "    \n",
    "def severity_score_exp(severity_rating):\n",
    "    if severity_rating == \"low\":\n",
    "        return np.exp(1)\n",
    "    elif severity_rating == \"moderate\":\n",
    "        return np.exp(2)\n",
    "    elif severity_rating == \"medium\":\n",
    "        return np.exp(3)\n",
    "    elif severity_rating == \"high\":\n",
    "        return np.exp(4)\n",
    "    elif severity_rating == \"extreme\":\n",
    "        return np.exp(5)\n",
    "    else:\n",
    "        return np.exp(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "severity_score_udf = udf(lambda severity: \n",
    "                         severity_score(severity), \n",
    "                         FloatType\n",
    "                        )\n",
    "\n",
    "severity_quadratic_udf = udf(lambda severity: \n",
    "                             severity_score_quadratic(severity), \n",
    "                             FloatType\n",
    "                            )\n",
    "\n",
    "severity_logarithmic_udf = udf(lambda severity: \n",
    "                  severity_score_log(severity), \n",
    "                  FloatType\n",
    "                 )\n",
    "\n",
    "severity_exponential_udf = udf(lambda severity: \n",
    "                    severity_score_exp(severity), \n",
    "                    FloatType\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-29T14:37:41.903240Z",
     "start_time": "2017-06-29T14:37:40.491639Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-60d7d55c1ca6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Drop Nulls - will revisit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mreports_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Keep only target columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data_df' is not defined"
     ]
    }
   ],
   "source": [
    "# Load Data\n",
    "reports_df = spark.read.csv(data_filepath,\n",
    "                         sep=\"\\t\",\n",
    "                         schema=schema,\n",
    "                         header=None,\n",
    "                         quote='\"')\n",
    "\n",
    "# Drop Nulls - will revisit\n",
    "reports_df = reports_df.dropna()\n",
    "\n",
    "# Keep only target columns\n",
    "reports_df = reports_df.select([column for column in target_columns])\n",
    "\n",
    "# Create Lat/Long columns\n",
    "reports_df = reports_df.withColumn(\"Lat/Long\",\n",
    "                                   struct(reports_df.lat, reports_df.lon))\n",
    "\n",
    "# Create Severity Features columns\n",
    "\n",
    "\n",
    "# Convert Timestamps to date time groups\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-29T11:52:49.613715Z",
     "start_time": "2017-06-29T11:52:49.537579Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- lat: float (nullable = true)\n",
      " |-- lon: float (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- created_on: integer (nullable = true)\n",
      " |-- start_ts: integer (nullable = true)\n",
      " |-- report_type: string (nullable = true)\n",
      " |-- severity: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(lat=37.98381042480469, lon=23.7275390625, id=u'KFg4bXSq5hGyhPkeGX1vrg', title=u'Security Message for U.S. Citizens: Athens (Greece), Planned Demonstration on November 14', created_on=1481760000, start_ts=1479132770, report_type=u'OSAC', severity=u'unrated')]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reports_df.printSchema()\n",
    "reports_df.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Reports with Cities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Cities Data and Build Lat/Long Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-29T14:11:59.286181Z",
     "start_time": "2017-06-29T14:11:59.212732Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "u'Path does not exist: file:/Users/brendandorsey/G_Data_Science/G_Repos/data/cities300000.csv;'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-148-8a584f687735>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcities_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../data/cities300000.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcities_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/2.1.1/libexec/python/pyspark/sql/readwriter.pyc\u001b[0m in \u001b[0;36mcsv\u001b[0;34m(self, path, schema, sep, encoding, quote, escape, comment, header, inferSchema, ignoreLeadingWhiteSpace, ignoreTrailingWhiteSpace, nullValue, nanValue, positiveInf, negativeInf, dateFormat, timestampFormat, maxColumns, maxCharsPerColumn, maxMalformedLogPerPartition, mode)\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasestring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m             \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_spark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPythonUtils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoSeq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0msince\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/2.1.1/libexec/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1131\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1133\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/2.1.1/libexec/python/pyspark/sql/utils.pyc\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     67\u001b[0m                                              e.java_exception.getStackTrace()))\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.AnalysisException: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.catalyst.analysis'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: u'Path does not exist: file:/Users/brendandorsey/G_Data_Science/G_Repos/data/cities300000.csv;'"
     ]
    }
   ],
   "source": [
    "cities_df = spark.read.csv(\"../data/cities300000.csv\")\n",
    "cities_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Haversine Distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply City Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Series Analysis\n",
    "\n",
    "Show several cities, then Berlin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
